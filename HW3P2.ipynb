{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykh8vQc0p71n"
      },
      "source": [
        "# 11785 HW3P2: Automatic Speech Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq0m4w_KkMeQ"
      },
      "source": [
        "Welcome to HW3P2. In this homework, you will be using the same data from HW1 but will be incorporating sequence models. We recommend you get familaried with sequential data and the working of RNNs, LSTMs and GRUs to have a smooth learning in this part of the homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEEll1kGkhcR"
      },
      "source": [
        "Disclaimer: This starter notebook will not be as elaborate as that of HW1P2 or HW2P2. You will need to do most of the implementation in this notebook because, it is expected after 2 HWs, you will be in a position to write a notebook from scratch. You are welcomed to reuse the code from the previous starter notebooks but may also need to make appropriate changes for this homework. <br>\n",
        "We have also given you 3 log files for the Very Low Cutoff (Levenshtein Distance = 30) so that you can observe how loss decreases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHGaJ_8tx_5Z"
      },
      "source": [
        "Common errors which you may face\n",
        "\n",
        "\n",
        "*   Shape errors: Half of the errors from this homework will account to this category. Try printing the shapes between intermediate steps to debug\n",
        "*   CUDA out of Memory: When your architecture has a lot of parameters, this can happen. Golden keys for this is, (1) Reducing batch_size (2) Call *torch.cuda.empty_cache* often, even inside your training loop, (3) Call *gc.collect* if it helps and (4) Restart run time if nothing works\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_fwJWcpqJDR"
      },
      "source": [
        "# Prelimilaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leymyQ-apwT6"
      },
      "source": [
        "You will need to install packages for decoding and calculating the Levenshtein distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:32:17.04284Z",
          "iopub.status.busy": "2022-04-04T06:32:17.04258Z",
          "iopub.status.idle": "2022-04-04T06:36:49.959767Z",
          "shell.execute_reply": "2022-04-04T06:36:49.958636Z",
          "shell.execute_reply.started": "2022-04-04T06:32:17.04281Z"
        },
        "id": "ZCQtZtkaTrcn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install python-Levenshtein\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd ..\n",
        "\n",
        "!pip install torchsummaryX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIi0Big7vPa9"
      },
      "source": [
        "# Kaggle (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6gTI0Rslxrr"
      },
      "source": [
        "You need to set up your Kaggle and download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPBUd7Cnl-Rx"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade --force-reinstall --no-deps kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if2Somqfbje1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-03T23:10:05.362976Z",
          "iopub.status.busy": "2022-04-03T23:10:05.362743Z",
          "iopub.status.idle": "2022-04-03T23:10:06.346302Z",
          "shell.execute_reply": "2022-04-03T23:10:06.345455Z",
          "shell.execute_reply.started": "2022-04-03T23:10:05.362948Z"
        },
        "id": "VOchVaRSjTUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "! kaggle competitions download -c 11-785-s22-hw3p2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDJTfvQubkLi"
      },
      "outputs": [],
      "source": [
        "! unzip -q /content/11-785-s22-hw3p2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:36:49.964159Z",
          "iopub.status.busy": "2022-04-04T06:36:49.963899Z",
          "iopub.status.idle": "2022-04-04T06:36:50.763639Z",
          "shell.execute_reply": "2022-04-04T06:36:50.762834Z",
          "shell.execute_reply.started": "2022-04-04T06:36:49.964128Z"
        },
        "id": "ff3fAWNh06Yw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "import csv\n",
        "\n",
        "import ctcdecode\n",
        "import Levenshtein\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUCKqm1ST1sU"
      },
      "source": [
        "# Dataset and dataloading (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:36:50.765286Z",
          "iopub.status.busy": "2022-04-04T06:36:50.765033Z",
          "iopub.status.idle": "2022-04-04T06:36:50.771867Z",
          "shell.execute_reply": "2022-04-04T06:36:50.771056Z",
          "shell.execute_reply.started": "2022-04-04T06:36:50.765251Z"
        },
        "id": "-PjVxPCBvVR6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import phonemes\n",
        "\n",
        "PHONEME_MAP = [\n",
        "    \" \",\n",
        "    \".\", #SIL\n",
        "    \"a\", #AA\n",
        "    \"A\", #AE\n",
        "    \"h\", #AH\n",
        "    \"o\", #AO\n",
        "    \"w\", #AW\n",
        "    \"y\", #AY\n",
        "    \"b\", #B\n",
        "    \"c\", #CH\n",
        "    \"d\", #D\n",
        "    \"D\", #DH\n",
        "    \"e\", #EH\n",
        "    \"r\", #ER\n",
        "    \"E\", #EY\n",
        "    \"f\", #F\n",
        "    \"g\", #G\n",
        "    \"H\", #H\n",
        "    \"i\", #IH \n",
        "    \"I\", #IY\n",
        "    \"j\", #JH\n",
        "    \"k\", #K\n",
        "    \"l\", #L\n",
        "    \"m\", #M\n",
        "    \"n\", #N\n",
        "    \"N\", #NG\n",
        "    \"O\", #OW\n",
        "    \"Y\", #OY\n",
        "    \"p\", #P \n",
        "    \"R\", #R\n",
        "    \"s\", #S\n",
        "    \"S\", #SH\n",
        "    \"t\", #T\n",
        "    \"T\", #TH\n",
        "    \"u\", #UH\n",
        "    \"U\", #UW\n",
        "    \"v\", #V\n",
        "    \"W\", #W\n",
        "    \"?\", #Y\n",
        "    \"z\", #Z\n",
        "    \"Z\" #ZH\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:36:50.776514Z",
          "iopub.status.busy": "2022-04-04T06:36:50.776319Z",
          "iopub.status.idle": "2022-04-04T06:36:50.782916Z",
          "shell.execute_reply": "2022-04-04T06:36:50.78211Z",
          "shell.execute_reply.started": "2022-04-04T06:36:50.776484Z"
        },
        "id": "ZsHfhDcNUevH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def parse_csv(filepath):\n",
        "    subset = []\n",
        "    with open(filepath) as f:\n",
        "        f_csv = csv.reader(f)\n",
        "        for row in f_csv:\n",
        "            subset.append(row[0])\n",
        "    return subset[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:36:50.784672Z",
          "iopub.status.busy": "2022-04-04T06:36:50.78434Z",
          "iopub.status.idle": "2022-04-04T06:36:50.801454Z",
          "shell.execute_reply": "2022-04-04T06:36:50.800724Z",
          "shell.execute_reply.started": "2022-04-04T06:36:50.784636Z"
        },
        "id": "8SndiVRVqBMa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class LibriSamples(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path, partition= \"train\"):\n",
        "\n",
        "        self.X_dir = data_path + '/' + partition + '/mfcc/'\n",
        "        self.Y_dir = data_path + '/' + partition + '/transcript/'\n",
        "\n",
        "        self.X_files = os.listdir(self.X_dir)\n",
        "        self.Y_files = os.listdir(self.Y_dir)\n",
        "\n",
        "        self.PHONEMES = phonemes.PHONEMES\n",
        "        \n",
        "        assert(len(self.X_files) == len(self.Y_files))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_files)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "    \n",
        "        X = np.load(self.X_dir + self.X_files[ind])\n",
        "        Y = np.load(self.Y_dir + self.Y_files[ind])\n",
        "\n",
        "        Y = Y[1:-1]\n",
        "        Yy = [self.PHONEMES.index(yy) for yy in Y]\n",
        "\n",
        "        return (torch.tensor(X), torch.tensor(Yy, dtype=torch.long))\n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "        \n",
        "        batch_x = [x for x,y in batch]\n",
        "        batch_y = [y for x,y in batch]\n",
        "\n",
        "        indexes = np.random.choice(np.arange(batch_size+1), 20)\n",
        "\n",
        "        batch_x_pad = pad_sequence(batch_x, batch_first = True)\n",
        "        lengths_x = [len(x) for x in batch_x]\n",
        "\n",
        "        batch_y_pad = pad_sequence(batch_y, batch_first = True)\n",
        "        lengths_y = [len(y) for y in batch_y]\n",
        "\n",
        "        return batch_x_pad, batch_y_pad, torch.tensor(lengths_x), torch.tensor(lengths_y)\n",
        "\n",
        "class LibriSamplesTest(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path):\n",
        "\n",
        "        test_order_list = parse_csv('/content/hw3p2_student_data/hw3p2_student_data/test/test_order.csv')\n",
        "        self.X_path = data_path + '/test/mfcc/'\n",
        "        self.X = [np.load(self.X_path + file) for file in test_order_list]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, ind):\n",
        "        return torch.tensor(self.X[ind])\n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "        \n",
        "        batch_x = [x for x in batch]\n",
        "        batch_x_pad = pad_sequence(batch_x, batch_first = True)\n",
        "        lengths_x = [len(x) for x in batch_x]\n",
        "\n",
        "        return batch_x_pad, torch.tensor(lengths_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:36:50.803135Z",
          "iopub.status.busy": "2022-04-04T06:36:50.802815Z",
          "iopub.status.idle": "2022-04-04T06:37:09.915484Z",
          "shell.execute_reply": "2022-04-04T06:37:09.914689Z",
          "shell.execute_reply.started": "2022-04-04T06:36:50.803101Z"
        },
        "id": "4mzoYfTKu14s",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "root = '/content/hw3p2_student_data/hw3p2_student_data'\n",
        "\n",
        "train_data = LibriSamples(root, 'train')\n",
        "val_data = LibriSamples(root, 'dev')\n",
        "test_data = LibriSamplesTest(root)\n",
        "\n",
        "train_loader = DataLoader(train_data, collate_fn = train_data.collate_fn, shuffle=True, batch_size = batch_size, num_workers = 4)\n",
        "val_loader = DataLoader(val_data, collate_fn = val_data.collate_fn, shuffle=True, batch_size = batch_size)\n",
        "test_loader = DataLoader(test_data, collate_fn = test_data.collate_fn, shuffle=False, batch_size = batch_size)\n",
        "\n",
        "print(\"Batch size: \", batch_size)\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:37:09.91714Z",
          "iopub.status.busy": "2022-04-04T06:37:09.916884Z",
          "iopub.status.idle": "2022-04-04T06:37:10.672795Z",
          "shell.execute_reply": "2022-04-04T06:37:10.671879Z",
          "shell.execute_reply.started": "2022-04-04T06:37:09.917106Z"
        },
        "id": "u9FwVZ9I2da0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for i, data in enumerate(val_loader):\n",
        "    x, y, lx, ly = data\n",
        "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly4mjUUUuJhy"
      },
      "source": [
        "# Model Configuration (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:37:10.674696Z",
          "iopub.status.busy": "2022-04-04T06:37:10.6744Z",
          "iopub.status.idle": "2022-04-04T06:37:10.683527Z",
          "shell.execute_reply": "2022-04-04T06:37:10.68264Z",
          "shell.execute_reply.started": "2022-04-04T06:37:10.674664Z"
        },
        "id": "N5wxznJNgc6r",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self, p=0.5):\n",
        "        self.p = p\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or not self.p:\n",
        "            return x\n",
        "        x = x.clone()\n",
        "        mask = x.new_empty(1, x.size(1), x.size(2), requires_grad=False).bernoulli_(1 - self.p)\n",
        "        mask = mask.div_(1 - self.p)\n",
        "        mask = mask.expand_as(x)\n",
        "        return x * mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:37:10.685444Z",
          "iopub.status.busy": "2022-04-04T06:37:10.685136Z",
          "iopub.status.idle": "2022-04-04T06:37:10.69572Z",
          "shell.execute_reply": "2022-04-04T06:37:10.694698Z",
          "shell.execute_reply.started": "2022-04-04T06:37:10.685397Z"
        },
        "id": "kXStdh4ldHsz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class NextBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, i):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            nn.Conv1d(in_channels = in_channels, out_channels = out_channels, bias = False, padding = 0, kernel_size = 1, stride = 1),\n",
        "            nn.BatchNorm1d(out_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Conv1d(in_channels = out_channels, out_channels = out_channels, bias = False, padding = 1, kernel_size = 3, stride = 1, groups = out_channels),\n",
        "            nn.BatchNorm1d(out_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Conv1d(in_channels = out_channels, out_channels = in_channels, bias = False, padding = 0,  kernel_size = 1, stride = 1),\n",
        "            nn.BatchNorm1d(in_channels),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = out + x\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:37:10.699752Z",
          "iopub.status.busy": "2022-04-04T06:37:10.699465Z",
          "iopub.status.idle": "2022-04-04T06:37:10.708955Z",
          "shell.execute_reply": "2022-04-04T06:37:10.70734Z",
          "shell.execute_reply.started": "2022-04-04T06:37:10.699713Z"
        },
        "id": "LIJcqvYfTJhz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Downsample(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.downsample = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, in_channels * 2, kernel_size = 2, stride = 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.downsample(x)\n",
        "        return out "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:37:10.711262Z",
          "iopub.status.busy": "2022-04-04T06:37:10.710834Z",
          "iopub.status.idle": "2022-04-04T06:37:20.166603Z",
          "shell.execute_reply": "2022-04-04T06:37:20.165867Z",
          "shell.execute_reply.started": "2022-04-04T06:37:10.71113Z"
        },
        "id": "CGoiXd70tb5z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.embedding_stem = nn.Conv1d(in_channels = 13, out_channels = 64, bias = False, kernel_size = 3, padding = 1, stride = 1)\n",
        "\n",
        "        self.stages = [\n",
        "            [64, 256, 2],\n",
        "            [128, 512, 2],\n",
        "            [256, 1024, 2],\n",
        "        ]\n",
        "\n",
        "        layers = self.make_layers()\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        final_classes = self.stages[-1][0]\n",
        "    \n",
        "        self.lstm_base = nn.LSTM(input_size = 256, hidden_size = 512, batch_first = True, bidirectional = True, bias = True)\n",
        "        self.lstm1 = nn.LSTM(input_size = 1024, hidden_size = 512, batch_first = True, bidirectional = True, bias = True)\n",
        "        self.lstm2 = nn.LSTM(input_size = 1024, hidden_size = 512, batch_first = True, bidirectional = True, bias = True)\n",
        "        self.lstm3 = nn.LSTM(input_size = 1024, hidden_size = 512, batch_first = True, bidirectional = True, bias = True)\n",
        "\n",
        "        \n",
        "        self.lockdrop = LockedDropout(0.4)\n",
        "\n",
        "        self.classification = nn.Sequential(\n",
        "            nn.Linear((512 * 2), 2048),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(2048, 41)\n",
        "        )\n",
        "        self.logSoftmax = nn.LogSoftmax(dim = 2)\n",
        "\n",
        "    def make_layers(self):\n",
        "        layers = []\n",
        "        for idx, curr_stage in enumerate(self.stages):\n",
        "            in_channels, out_channels, num_blocks = curr_stage\n",
        "            for j in range(num_blocks):\n",
        "                layers.append(NextBlock(in_channels = in_channels,out_channels=out_channels, i = j))\n",
        " \n",
        "            if(idx != len(self.stages)-1):\n",
        "                layers.append(Downsample(in_channels = in_channels))\n",
        "\n",
        "        return layers\n",
        "\n",
        "    def forward(self, x, lx):\n",
        "        out = torch.permute(x, (0,2,1))\n",
        "        out = self.embedding_stem(out)\n",
        "        out = self.layers(out)\n",
        "\n",
        "        out = torch.permute(out, (0,2,1))\n",
        "        lx = lx // 4\n",
        "        \n",
        "        packed_input = pack_padded_sequence(out, lx, batch_first = True, enforce_sorted = False)\n",
        "\n",
        "\n",
        "        for i in range(0,4):\n",
        "            lstm = None\n",
        "            if i == 0:\n",
        "                lstm = self.lstm_base\n",
        "            elif i == 1:\n",
        "                lstm = self.lstm1\n",
        "            elif i == 2:\n",
        "                lstm = self.lstm2\n",
        "            elif i == 3:\n",
        "                lstm = self.lstm3\n",
        "\n",
        "            out1, (out2, out3) = lstm(packed_input)\n",
        "            \n",
        "                # out1, (out2, out3) = self.lstm(packed_input)\n",
        "\n",
        "            out, lengths  = pad_packed_sequence(out1, batch_first = True)\n",
        "            \n",
        "            out = torch.permute(out, (1,0,2))\n",
        "            out = self.lockdrop(out)\n",
        "            out = torch.permute(out, (1,0,2))\n",
        "\n",
        "            packed_input = pack_padded_sequence(out, lengths, batch_first = True, enforce_sorted = False)\n",
        "\n",
        "        # out1, (out2, out3) = self.lstm(packed_input)\n",
        "        # out, lengths  = pad_packed_sequence(out1, batch_first = False)\n",
        "        \n",
        "        out = self.classification(out)\n",
        "        out = self.logSoftmax(out)        \n",
        "\n",
        "        return out, lx\n",
        "\n",
        "model = Network().to(device)\n",
        "summary(model, x.to(device), lx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training Configuration (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T06:37:20.168568Z",
          "iopub.status.busy": "2022-04-04T06:37:20.168087Z",
          "iopub.status.idle": "2022-04-04T06:37:20.175473Z",
          "shell.execute_reply": "2022-04-04T06:37:20.174656Z",
          "shell.execute_reply.started": "2022-04-04T06:37:20.168531Z"
        },
        "id": "iGoozH2nd6KB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "criterion = nn.CTCLoss()\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.AdamW(params = model.parameters(), lr = lr, weight_decay = 2e-3)\n",
        "decoder = CTCBeamDecoder(labels = PHONEME_MAP, beam_width = 2, log_probs_input = True)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer = optimizer, mode='min', factor = 0.5, patience = 4, threshold = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-04T06:37:20.243242Z",
          "iopub.status.idle": "2022-04-04T06:37:20.243919Z",
          "shell.execute_reply": "2022-04-04T06:37:20.243672Z",
          "shell.execute_reply.started": "2022-04-04T06:37:20.243644Z"
        },
        "id": "KEuvs3Kje47-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def calculate_levenshtein(h, y, lh, ly, decoder, PHONEME_MAP):\n",
        "    batch_size = h.shape[0]\n",
        "    dist = 0\n",
        "    beam_results, beam_scores, timesteps, out_lens = decoder.decode(h, seq_lens = lh)\n",
        "    for i in range(batch_size): \n",
        "        beam = beam_results[i][0][:out_lens[i][0]]\n",
        "\n",
        "        h_string = \"\".join([PHONEME_MAP[x] for x in beam])\n",
        "\n",
        "        y_sliced = y[i,0:ly[i]]\n",
        "        y_string = \"\".join([PHONEME_MAP[x] for x in y_sliced])\n",
        "        \n",
        "        dist += Levenshtein.distance(h_string, y_string)\n",
        "\n",
        "    dist /= batch_size\n",
        "\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-03T23:14:42.796983Z",
          "iopub.status.busy": "2022-04-03T23:14:42.794096Z",
          "iopub.status.idle": "2022-04-03T23:14:42.818399Z",
          "shell.execute_reply": "2022-04-03T23:14:42.817664Z",
          "shell.execute_reply.started": "2022-04-03T23:14:42.796931Z"
        },
        "id": "d7b7iY0we8Kj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "    for i, data in (enumerate(train_loader)):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs, opLength = model(x, lx)\n",
        "            outputs = torch.permute(outputs, (1,0,2))\n",
        "            loss = criterion(outputs, y, opLength, ly)\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))))\n",
        "        scaler.scale(loss).backward() \n",
        "        scaler.step(optimizer) \n",
        "        scaler.update()\n",
        "        bar.update()\n",
        "\n",
        "    total_loss /= len(train_loader)\n",
        "\n",
        "    return total_loss\n",
        "    \n",
        "def validate(model, val_loader, optimizer, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    distance = 0\n",
        "    bar = tqdm(total=len(val_loader), dynamic_ncols=True, leave=False, position=0, desc='Validation')\n",
        "    for i, data in (enumerate(val_loader)):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs, opLength = model(x, lx)\n",
        "            outputs = torch.permute(outputs, (1,0,2))\n",
        "            loss = criterion(outputs, y, opLength, ly)\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        outputs = torch.permute(outputs, (1,0,2))\n",
        "        distance += calculate_levenshtein(outputs, y, opLength, ly, decoder, PHONEME_MAP) \n",
        "        bar.update()\n",
        "\n",
        "    total_loss /= len(val_loader)\n",
        "    distance /= len(val_loader)\n",
        "    return total_loss, distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-03T23:15:36.319579Z",
          "iopub.status.busy": "2022-04-03T23:15:36.318811Z",
          "iopub.status.idle": "2022-04-04T05:46:37.730296Z",
          "shell.execute_reply": "2022-04-04T05:46:37.729423Z",
          "shell.execute_reply.started": "2022-04-03T23:15:36.319536Z"
        },
        "id": "axdHmg8-5ZlE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for i in range(1,61):\n",
        "    print('Epoch', i)\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_distance = validate(model, val_loader, optimizer, criterion)\n",
        "    \n",
        "    scheduler.step(val_distance)\n",
        "    print(scheduler._last_lr)\n",
        "\n",
        "    if i > 20 and i % 5 == 0:\n",
        "        checkpoint = { \n",
        "            'epoch': i,\n",
        "            'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'lr_sched': scheduler\n",
        "        }\n",
        "        prev_loss = val_loss\n",
        "        torch.save(checkpoint, '/content/drive/MyDrive/hw3p2/model'+str(i)+'.pth')\n",
        "\n",
        "    print('Training Loss', train_loss)\n",
        "    print('Validation Loss', val_loss)\n",
        "    print('Validation distance', val_distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T05:50:34.461514Z",
          "iopub.status.busy": "2022-04-04T05:50:34.461248Z",
          "iopub.status.idle": "2022-04-04T05:50:34.468225Z",
          "shell.execute_reply": "2022-04-04T05:50:34.467136Z",
          "shell.execute_reply.started": "2022-04-04T05:50:34.461485Z"
        },
        "id": "OKEPzNSW0g6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_decoder = CTCBeamDecoder(labels = PHONEME_MAP, beam_width = 20, log_probs_input = True)\n",
        "def getPhonemes(h, lh):\n",
        "    h_string = []\n",
        "    batch_size = h.shape[0]\n",
        "    dist = 0\n",
        "    beam_results, beam_scores, timesteps, out_lens = test_decoder.decode(h, seq_lens = lh)\n",
        "    for i in range(batch_size): \n",
        "        beam = beam_results[i][0][:out_lens[i][0]]\n",
        "        h_string.append(\"\".join([PHONEME_MAP[x] for x in beam]))\n",
        "\n",
        "    return h_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T05:50:45.528644Z",
          "iopub.status.busy": "2022-04-04T05:50:45.527985Z",
          "iopub.status.idle": "2022-04-04T05:50:45.53578Z",
          "shell.execute_reply": "2022-04-04T05:50:45.535056Z",
          "shell.execute_reply.started": "2022-04-04T05:50:45.528608Z"
        },
        "id": "V7EVh1Lqda6S",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader):\n",
        "    tid = 0\n",
        "    model.eval()\n",
        "    bar = tqdm(total=len(test_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "    with open(\"verification_early_submission.csv\", \"w+\") as f:\n",
        "        f.write(\"id,predictions\\n\")\n",
        "        for i, data in enumerate(test_loader):\n",
        "            x = data[0].cuda()\n",
        "            lx = data[1]\n",
        "            output, lh = model(x, lx)\n",
        "            opString = getPhonemes(output, lh)\n",
        "            for output in opString:\n",
        "                f.write(\"{},{}\\n\".format(tid, output))\n",
        "                tid += 1\n",
        "            bar.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T05:50:47.515597Z",
          "iopub.status.busy": "2022-04-04T05:50:47.515333Z",
          "iopub.status.idle": "2022-04-04T05:51:47.827396Z",
          "shell.execute_reply": "2022-04-04T05:51:47.826701Z",
          "shell.execute_reply.started": "2022-04-04T05:50:47.515569Z"
        },
        "id": "3PJuJvzw2xiY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROrqXnNqzJSc"
      },
      "source": [
        "# Submit to kaggle (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-04T05:52:43.906532Z",
          "iopub.status.busy": "2022-04-04T05:52:43.905912Z",
          "iopub.status.idle": "2022-04-04T05:52:44.942061Z",
          "shell.execute_reply": "2022-04-04T05:52:44.941077Z",
          "shell.execute_reply.started": "2022-04-04T05:52:43.906494Z"
        },
        "id": "R-SU9fZ3xHtk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "! kaggle competitions submit -c 11-785-s22-hw3p2 -f /content/verification_early_submission.csv -m \"Message\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE1hRnvf0bFz"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JirZTmqequxj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "HW3P2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
